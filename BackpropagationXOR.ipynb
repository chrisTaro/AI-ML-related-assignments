{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BackpropagationXOR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kLc3-0zYxdY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7f816e88-9c79-4b9e-d5ab-f3c7dc249a47"
      },
      "source": [
        "# CS461 - Coding Assignment\n",
        "# BackpropagationXOR.ipynb\n",
        "# By: Christian Magpantay\n",
        "# Code Referenced/Used: \n",
        "# https://iamtrask.github.io/2015/07/12/basic-python-network/\n",
        "# Create a Neural Network with backpropagation learning algorithm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# sigmoid function\n",
        "def nonlin(x,deriv=False):\n",
        "  if(deriv==True):\n",
        "    return x*(1-x)\n",
        "  return 1/(1+np.exp(-x))\n",
        " \n",
        "# input dataset\n",
        "X = np.array([  [0,0],\n",
        "                [0,1],\n",
        "                [1,0],\n",
        "                [1,1] ]) # 4x1\n",
        " \n",
        "# desired output dataset           \n",
        "y = np.array([[0,1,1,0]]).T # 1x4\n",
        "\n",
        "# create neurons with 2 inputs, 2 hidden,\n",
        "# and 1 output\n",
        "inputs = hidden = 2\n",
        "output = 1\n",
        "\n",
        "# initialize weights randomly, synapses\n",
        "np.random.seed(1)\n",
        "syn0 = 2*np.random.random((inputs, hidden)) - 1 # 2X2\n",
        "syn1 = 2*np.random.random((hidden, output)) - 1 # 2X1\n",
        " \n",
        "# start neural network\n",
        "for i in range(10000):\n",
        "  # forward propagate using logistic activation function\n",
        "  l0 = X                        # inputs, neurons 0 & 1\n",
        "  l1 = nonlin(np.dot(l0,syn0))  # neurons 2 & 3 outputs, from input to hidden\n",
        "  l2 = nonlin(np.dot(l1,syn1))  # neuron 4 outputs, from hidden to output\n",
        "\n",
        "  # now, backpropagate \n",
        "  # start by taking the difference of the matrices, targets and observed\n",
        "  # then multiplying it with the derivative of the activation function\n",
        "  # the result is the deltas of neuron 4, then average all deltas.\n",
        "  #\n",
        "  # use average of all deltas for matrix between input and hidden thus\n",
        "  # creating the errors needed mutiplying it with the derivative of the\n",
        "  # activation function then average all deltas in this matrix.\n",
        "  #\n",
        "  # next, find the partial derivative of the error with respect to weights  \n",
        "  # of each 2 to 4 and 3 to 4\n",
        "  # then multiplying respective weights with the respective outputs with\n",
        "  # the average of deltas of neuron 4\n",
        "  # i.e weight,2 to 4 with output neuron 2 with the sum of deltas of neuron 4\n",
        "  # \n",
        "  # take the result from previous step and multiply it with the negative outputs\n",
        "  # 2 & 3 for hidden to output layer and 0 & 1 for input to hidden layer\n",
        "  #\n",
        "  # average the result and add this number to weights, updating as new weights\n",
        "  # repeat algorithm as necessary\n",
        "  l2_error = y - l2\n",
        "  l2_delta = nonlin(l2,deriv=True)*l2_error       # delta 4 = f'(net4)(t4-y4)\n",
        "\n",
        "  al2 = np.average(l2_delta)                      # avg of delta 4\n",
        "\n",
        "  l2_delta_avg = np.array([[al2,al2,al2,al2]]).T  # create array to dot product\n",
        "                                                  # avg delta with outputs 2 & 3\n",
        "\n",
        "  # proceed for input to hidden matrix using avg of deltas and weights to 2 & 3\n",
        "  l1_error = l2_delta.dot(syn1.T)                 # outputs 2 & 3 dot product\n",
        "                                                  # with deltas in \n",
        "                                                  # neuron 4 to create error\n",
        "                                                  # matrix between input\n",
        "                                                  # and hidden layers\n",
        "\n",
        "  l1_delta = nonlin(l1,deriv=True)*l1_error       # multiply error with\n",
        "                                                  # derivative of log. act. func\n",
        "                                                  # delta2&3 = f'(net2&3)sum\n",
        "\n",
        "  al1 = np.average(l1_delta, axis = 0)            # average all deltas\n",
        "                                             \n",
        "  l1_delta_avg = np.array([al1,al1,al1,al1])      # create array to dot product\n",
        "                                                  # avg delta with outputs 0 & 1\n",
        "                           \n",
        "  # proceed now to update weights E/w = -(output) * delta \n",
        "  negl1 = np.negative(l1)                         # -output neurons 0 & 1\n",
        "  negl2 = np.negative(l2)                         # -output neurons 2 & 3\n",
        "\n",
        "  ea0 = np.average(negl1.T.dot(l1_delta_avg), axis=0) # avg of errors from\n",
        "                                                  # neurons 0 to 2, 3\n",
        "                                                  # neurons 1 to 2, 3\n",
        "                                                  # -(output) * delta\n",
        "\n",
        "  ea1 = np.average(negl2.T.dot(l2_delta_avg))     # avg of errors from\n",
        "                                                  # neurons 2 to 4\n",
        "                                                  # neurons 3 to 4\n",
        "                                                  # -(output) * delta\n",
        "\n",
        "\n",
        "  erroravg_0 = np.array([ea0,ea0])                # array to dot product with \n",
        "                                                  # matrix input to hidden\n",
        "\n",
        "  erroravg_1 = np.array([[ea1,ea1]]).T            # array to dot product with \n",
        "                                                  # matrix hidden to output\n",
        "\n",
        "  # update weights\n",
        "  syn0 += erroravg_0                              # weights input to hidden\n",
        "  syn1 += erroravg_1                              # weights hidden to ouput\n",
        "  # end loop\n",
        "\n",
        "print(\"Output After Training:\")\n",
        "print(l2)                                         # print result\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output After Training:\n",
            "[[0.03556723]\n",
            " [0.00258891]\n",
            " [0.00182685]\n",
            " [0.00140452]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}